#!/usr/bin/env python
import os
import sys
import logging
logger = logging.getLogger("ODRIVE_BUILD")

import subprocess
import tarfile
import errno
import shutil
import sys
#import commands
import re

import argparse
import textwrap
from contextlib import closing
from glob import glob

PROJECT_ROOT = os.path.join(os.getenv("GOPATH"), "src", "bitbucket.di2e.net", "dime", "object-drive-server")

"""
Map of repo names to their valid git remotes, and the branch to checkout.
"""
GIT_DEPENDENCIES = {
    'object-drive-ui':
        ('ssh://git@bitbucket.di2e.net:7999/dime/object-drive-ui.git', 'develop'),
    'dias-simulator':
        ('ssh://git@bitbucket.di2e.net:7999/dime/dias-simulator.git', 'master'),
}

"""
These programs must be available for build in a dev environment.
The format of the tuples in this list is
('command name', 'version command', 'help text',)
but any no-op argument to the command will do. The call to subprocess.Popen()
using the commands listed here simply checks if they exist in the environment.
"""
COMMANDS_REQUIRED = [
    ('npm', 'version', ''),
    ('gulp', 'version', 'gulp must be installed globally\n\tTry `npm install gulp -g`'),
    ('docker', 'version', ''),
    ('docker-compose', 'ps', ''),
    ('go-bindata', '-version', 'go-bindata not installed\n\tTry `go get -u github.com/jteeuwen/go-bindata/...`'),
    ('govendor', 'version', 'govendor not installed\n\tTry `go get -u github.com/kardianos/govendor`')
]


def odrive_build(tag="latest"):
    """ Build the odrive docker container.
    """
    
    odrive_dir = os.path.join(PROJECT_ROOT, 'docker', 'odrive')
    build_dir = os.path.join(odrive_dir, 'build')
    if os.path.exists(build_dir):
        logger.debug("removing previous build dir: {0}".format(build_dir))
        shutil.rmtree(build_dir)

    # Run `govendor sync` and copy source tree locally.
    os.chdir(PROJECT_ROOT)
    subprocess.check_call(['./makedocs'])
    subprocess.check_call(['govendor', 'sync'])
    
    # NOTE: we copy odrive source to a build dir, but exclude docker folder
    # list contents of dir
    go_packages = [pkg for pkg in filter(os.path.isdir, glob("*")) if not pkg == "docker"]

    # loop through that list and copy to build directory
    for pkg in go_packages:
        shutil.copytree(pkg, os.path.join(build_dir, pkg))
    
    os.chdir(odrive_dir)
    dockerfile = os.path.abspath("./Dockerfile")
    # Invoke the Dockerfile.
    run_dockerfile(dockerfile, "deciphernow/odrive", tag)
    # Clean up build directory.
    shutil.rmtree(build_dir)

def odrivebc_build(tag="latest"):
    """ Build the odrive boring crypto docker container.
    """
    
    odrivebc_dir = os.path.join(PROJECT_ROOT, 'docker', 'odrivebc')
    build_dir = os.path.join(odrivebc_dir, 'build')
    if os.path.exists(build_dir):
        logger.debug("removing previous build dir: {0}".format(build_dir))
        shutil.rmtree(build_dir)

    # Run `govendor sync` and copy source tree locally.
    os.chdir(PROJECT_ROOT)
    subprocess.check_call(['./makedocs'])
    subprocess.check_call(['govendor', 'sync'])
    
    # NOTE: we copy odrive source to a build dir, but exclude docker folder
    # list contents of dir
    go_packages = [pkg for pkg in filter(os.path.isdir, glob("*")) if not pkg == "docker"]

    # loop through that list and copy to build directory
    for pkg in go_packages:
        shutil.copytree(pkg, os.path.join(build_dir, pkg))
    
    os.chdir(odrivebc_dir)
    dockerfile = os.path.abspath("./Dockerfile")
    # Invoke the Dockerfile.
    run_dockerfile(dockerfile, "deciphernow/odrive-bc", tag)
    # Clean up build directory.
    shutil.rmtree(build_dir)

def metadatadb_build(tag="latest"):
    """ Build the database docker image 
    
    This provides the data store for odrive in the docker-compose cluster
    """
    
    #object_drive_server = PROJECT_ROOT
    defaultcerts = os.path.join(PROJECT_ROOT, 'defaultcerts')
    odrive_database = os.path.join(PROJECT_ROOT, 'cmd', 'odrive-database')
    metadatadb_dir = os.path.join(PROJECT_ROOT, 'docker', 'metadatadb')
    dockerfile = os.path.join(metadatadb_dir, "Dockerfile")

    # CROSS COMPILATION WOO HOO!
    os.chdir(odrive_database)
    os.putenv('GOOS', 'linux')
    os.putenv('GOARCH', 'amd64')
    if os.getenv('CGO_ENABLED') == None:
        os.putenv('CGO_ENABLED', '0')
    try:
        subprocess.check_call(["go-bindata", "schema", "migrations", "../../defaultcerts/client-mysql/id", "../../defaultcerts/client-mysql/trust"]) 
        subprocess.check_call(["go", "build"]) 
    except Exception as e:
        print(e)
        raise

    binary = os.path.join(odrive_database, "odrive-database")
    os.chdir(metadatadb_dir)
    shutil.copyfile(binary, "./odrive-database")

    # ca.pem
    ca_pem = os.path.join(defaultcerts, 'client-mysql', 'trust', 'ca.pem')
    shutil.copyfile(ca_pem, './ca.pem')
    # client-cert.pem
    client_cert_pem = os.path.join(defaultcerts, 'client-mysql', 'id', 'client-cert.pem')
    shutil.copyfile(client_cert_pem, './client-cert.pem')
    # client-key.pem
    client_key_pem = os.path.join(defaultcerts, 'client-mysql', 'id', 'client-key.pem')
    shutil.copyfile(client_key_pem, './client-key.pem')
    # server-cert.pem
    server_cert_pem = os.path.join(defaultcerts, 'metadatadb', 'id', 'server-cert.pem')
    shutil.copyfile(server_cert_pem, './server-cert.pem')
    # server-key.pem
    server_key_pem = os.path.join(defaultcerts, 'metadatadb', 'id', 'server-key.pem')
    shutil.copyfile(server_key_pem, './server-key.pem')

    # invoke docker build, and always try to clean up directory
    run_dockerfile(dockerfile, "deciphernow/metadatadb", tag)
    os.remove("odrive-database")


def gatekeeper_build(tag="latest"):
    gatekeeper_dir = os.path.join(PROJECT_ROOT, 'docker', 'gatekeeper')
    build_dir = os.path.join(gatekeeper_dir, 'build')

    if os.path.exists(build_dir):
        print('Build directory exists. Removing...')
        shutil.rmtree(build_dir)

    # Move checked-in resources/fs to build directory
    checked_in_resources = os.path.join(gatekeeper_dir, 'resources', 'fs')
    build_fs = os.path.join(build_dir, 'fs')
    shutil.copytree(checked_in_resources, build_fs)

    shutil.copyfile(os.path.join(PROJECT_ROOT,'defaultcerts','server','server.cert.pem'), os.path.join(gatekeeper_dir,'build','fs','etc','nginx','server.cert.pem'))
    shutil.copyfile(os.path.join(PROJECT_ROOT,'defaultcerts','server','server.key.pem'), os.path.join(gatekeeper_dir,'build','fs','etc','nginx','server.key.pem'))
    shutil.copyfile(os.path.join(PROJECT_ROOT,'defaultcerts','server','server.trust.pem'), os.path.join(gatekeeper_dir,'build','fs','etc','nginx','server.trust.pem'))
    # If an rpm was built, then bake it into the gatekeeper build
    od_root = os.getenv("OD_ROOT")
    if len(od_root) > 0 and os.path.exists(od_root):
        rpm_path = os.path.join(os.getenv("OD_ROOT"), "object-drive-ui", "rpm")
        rpm_location = glob(rpm_path + "/*.rpm")
        if len( rpm_location ) > 0:
            rpm_src = rpm_location[0]
            rpm_name = rpm_location[0].split(os.sep)[-1]
            rpm_dst = os.path.join(build_fs, rpm_name)
            shutil.copyfile(rpm_src, rpm_dst)
        else:
            print ("skipping rpm, as it is not found at %s" % rpm_path)
    else:
        self.logger.info("OD_ROOT is undefined. Skipping check for Object Drive UI RPM and installation")

    # tar up the fake filesystem
    tar_path = os.path.abspath(os.path.join(build_dir, 'fs'))
    tar_directory(tar_path, output_archive=os.path.join(gatekeeper_dir, 'fs.tgz'))

    # Run Docker Build
    dockerfile = os.path.join(PROJECT_ROOT, 'docker', 'gatekeeper', 'Dockerfile')
    run_dockerfile(dockerfile, 'deciphernow/gatekeeper', tag)    


def packaging_build(tag="latest"):
    """ Build the packager docker image
    
    """
    
    packaging_dir = os.path.join(PROJECT_ROOT, 'docker', 'packaging')
    build_dir = os.path.join(packaging_dir, 'build')
    if os.path.exists(build_dir):
        shutil.rmtree(build_dir)

    os.chdir(PROJECT_ROOT)
    
    # NOTE: we copy odrive source to a build dir, but exclude docker folder
    # list contents of dir
    go_packages = [pkg for pkg in filter(os.path.isdir, glob("*")) if not pkg == "docker"]

    # loop through that list and copy to build directory
    for pkg in go_packages:
        shutil.copytree(pkg, os.path.join(build_dir, pkg))

    os.chdir(packaging_dir)
    # Copy in custom RPM-building script for container
    build_script = "build_package_install.py"
    shutil.copyfile(build_script, os.path.join(build_dir, build_script))
    # Copy in custom env.sh-replacing and service wrapper
    wrapper = "service_wrapper.py"
    shutil.copyfile(wrapper, os.path.join(build_dir, wrapper))
    
    # Use our Dockerfile from this directory
    dockerfile = os.path.join(packaging_dir, "Dockerfile")
    run_dockerfile(dockerfile, "deciphernow/odriverpm", tag)
    shutil.rmtree(build_dir)

def packagingbc_build(tag="latest"):
    """ Build the packager docker image with rpm having odrive built with boring crypto
    
    """
    
    packagingbc_dir = os.path.join(PROJECT_ROOT, 'docker', 'packagingbc')
    build_dir = os.path.join(packagingbc_dir, 'build')
    if os.path.exists(build_dir):
        shutil.rmtree(build_dir)

    os.chdir(PROJECT_ROOT)
    
    # NOTE: we copy odrive source to a build dir, but exclude docker folder
    # list contents of dir
    go_packages = [pkg for pkg in filter(os.path.isdir, glob("*")) if not pkg == "docker"]

    # loop through that list and copy to build directory
    for pkg in go_packages:
        shutil.copytree(pkg, os.path.join(build_dir, pkg))

    os.chdir(packagingbc_dir)
    # Copy in custom RPM-building script for container
    build_script = "build_package_install.py"
    shutil.copyfile(build_script, os.path.join(build_dir, build_script))
    # Copy in custom env.sh-replacing and service wrapper
    wrapper = "service_wrapper.py"
    shutil.copyfile(wrapper, os.path.join(build_dir, wrapper))
    
    # Use our Dockerfile from this directory
    dockerfile = os.path.join(packagingbc_dir, "Dockerfile")
    run_dockerfile(dockerfile, "deciphernow/odriverpm-bc", tag)
    shutil.rmtree(build_dir)

def dias_build(self, tag="latest"):
    """ Build the dias simulator docker image
    """
    
    od_root = os.getenv("OD_ROOT")
    if len(od_root) > 0 and os.path.exists(od_root):
        dias_path = os.path.join(od_root, 'dias-simulator')
        if os.path.exists(dias_path):
            os.chdir(dias_path)
            dockerfile = os.path.abspath('./Dockerfile')
            run_dockerfile(dockerfile, "deciphernow/dias", tag)
        else:
            self.logger.info("DIAS Simulator not cloned into OD_ROOT at {0}. Check README.md. Skipping DIAS build.".format(dias_path))
    else:
        self.logger.info("OD_ROOT is undefined. Skipping DIAS build")
    

def run_dockerfile(dockerfile, image, tag="latest"):
    """ Runs the docker build for a given 
    
    Parameters:
    -----------
    dockerfile: str
        absolute path to Dockerfile
    image: str
        docker images name
    tag: str, opt
        Image tag. Defaults to "latest".
    """
    
    name_with_tag = image + ":" + tag
    try:
        build_dir = os.path.split(dockerfile)[0]
        subprocess.check_call(
                ['docker', 'build', '-t', name_with_tag, build_dir],
                stdout=sys.stdout, stderr=sys.stderr)
    except subprocess.CalledProcessError:
        raise


def clean_images(services):
    """ Remove service docker images.
    
    Parameters:
    -----------
    services: list
        Docker container names to be stopped and removed.
    """
    
    to_clean = []
    #output = commands.getoutput('docker images')
    p3sp=subprocess.Popen(["docker", "images"], stdout=subprocess.PIPE, stderr=subprocess.STDOUT)
    p3o=p3sp.communicate()[0]
    output = p3o

    # Output index 1 is one long string. Split on newlines.
    lines = output.split(b'\n')
    # Skip the header row
    for line in lines[1:]:
        if len(line) > 0:
            splitted = re.split(b'\s{2,}', line)
            repository, tag, image_id = splitted[0], splitted[1], splitted[2]
            if repository in services or repository == '<none>':
                logger.info(' Cleaning images:\t{0}\t{1}\t{2}'.format(repository, tag, image_id))
                to_clean.append(image_id)

    if not to_clean:
        return

    try:
        # Stop and remove containers.
        # TODO refactor to require a proper python install to allow proper pathing.
        os.chdir('docker')
        stop_cmd = ['docker-compose', 'stop']
        logger.info('Stopping containers...')
        subprocess.check_call(stop_cmd)
        logger.debug('Removing stopped containers...')
        # get stopped image ids
        #stopped = commands.getoutput('docker ps -f "status=exited" -q').split('\n')
        #stopped = subprocess.check_output('docker ps -f "status=exited" -q').split('\n')
        p3sp=subprocess.Popen(['docker','ps','-f','status=exited', '-q'], stdout=subprocess.PIPE, stderr=subprocess.STDOUT)
        p3o=p3sp.communicate()[0]
        stopped = p3o.split(b'\n')
        for container_id in stopped:
            if len(container_id) > 0:
                print(container_id)
                rm_stopped_cmd = ['docker', 'rm', '-f', container_id]
                if container_id:
                    subprocess.check_call(rm_stopped_cmd)
        rm_cmd = ['docker-compose', 'rm', '-f']
        subprocess.check_call(rm_cmd)
        cmd = ['docker', 'rmi', '-f']
        # Extend the argument list if a specific service was pass on the command line.
        cmd.extend(to_clean)
        subprocess.check_call(cmd, stdout=sys.stdout, stderr=sys.stderr)
        os.chdir('..')
    except subprocess.CalledProcessError:
        raise


def tar_directory(input, output_dir="build", output_archive=None):
    """
    Creates a .tar of the directory given as input. Input must be absolute path.
    Existing .tar files will be overwritten.
    Args:
        input: Absolute path to a directory, which will become the tar file.
        output_dir: Destination directory
        output_archive: The name of the tarball output. Defaults to the directory
        name passed as input.
    Returns: None
    """
    if not os.path.exists(input):
        raise ValueError("Argument to tar_directory must be absolute path to existing directory.")

    if output_archive is None:
        output_archive = os.path.split(input)[1] + '.tgz'

    def filter_osx_metadata(filename):
        return False if filename == ".DS_Store" else True

    import tarfile
    with closing(tarfile.open(output_archive, 'w:gz')) as t:
        for item in os.listdir(input):
            t.add(os.path.join(input, item), arcname=item)
    print("Created archive: {0}".format(output_archive))


class Builder(object):
    """
    Master class that coordinates the build. Create an instance, and invoke from a top-level script.
    """

    def __init__(self, required_commands=[], log_handler=None):
        if not isinstance(required_commands, list):
            raise TypeError("require_commands parameter must be a list of tuple.")

        if not log_handler:
            logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)
            self.logger = logging.getLogger('ODRIVE_BUILD')
        else:
            self.logger = log_handler 
            
        if not "OD_ROOT" in os.environ:
            ### TODO create this for the user?
            self.logger.info("OD_ROOT environment not set. No remote projects can be cloned locally")
        else:
            self.checkout_dir = os.getenv("OD_ROOT")
            self.logger.info("Setting checkout directory. Used if git clone is invoked: {0}".format(self.checkout_dir))
            
        self.env_commands = required_commands
        self.build_dir = os.getcwd()  # TODO look this up by GOPATH?
        self.devnull = open(os.devnull)        
        self.logger.info("Build directory: {0}".format(self.build_dir))
        

    def build_all(self):
        """ Run entire build process for odrive.
        
        Steps:
        1.  Inspect the environment to make sure variables are set and commands
            are available.
        2.  Clone necessary dependencies from github.
        3.  Build docker images for all necessary services.
        
        """
        
        self.inspect_toolchain()
        self.clone_branch('object-drive-ui', GIT_DEPENDENCIES['object-drive-ui'][0],
                             GIT_DEPENDENCIES['object-drive-ui'][1], build=False)
        self.clone_branch('dias-simulator', GIT_DEPENDENCIES['dias-simulator'][0],
                             GIT_DEPENDENCIES['dias-simulator'][1], build=False)

        self.docker('aac')
        odrive_build()
        odrivebc_build()
        metadatadb_build()
        gatekeeper_build()
        packaging_build()
        packagingbc_build()
        dias_build(self)
        
        self.logger.info("Build Finished")

    def build_named(self, image_name, tag='latest'):
        """ Build only the named image
        
        Parameters:
        -----------
        image_name: str
            name of the docker image to build.
        tag: str, opt
            name to tag the docker image with. 
        """
        
        if 'odrive-bc' in image_name:
            odrivebc_build(tag)
        elif 'odriverpm-bc' in image_name:
            packagingbc_build(tag)
        elif 'odriverpm' in image_name:
            packaging_build(tag)
        elif 'odrive' in image_name:
            odrive_build(tag)
        elif 'metadatadb' in image_name:
            metadatadb_build(tag)
        elif 'gatekeeper' in image_name:
            gatekeeper_build(tag)
        elif 'dias' in image_name:
            dias_build(self, tag)
        else:
            raise ValueError("Image name not known: {0}".format(image_name))

    def docker(self, service, service_type="script"):
        """
        Build docker images by calling out to their makeimage scripts.

        Args:
            service: A buildable image. The name should match a subdirectory of /docker as well
            as a service definition in /docker/docker-compose.yml
        """

        # script execution, ideally this is just for bash
        if service_type == "script":
            docker_service_dir = os.path.join(self.build_dir, 'docker', service)
            os.chdir(docker_service_dir)
            if not os.path.exists(os.path.join(docker_service_dir, 'makeimage')):
                self.logger.error("No makeimage script defined for {0}".format(service))
                sys.exit(1)
            try:
                subprocess.check_call(['./makeimage'])
            except subprocess.CalledProcessError as e:
                self.logger.error("Error from makeimage script for {0}: {1}".format(service, e))
                sys.exit(1)
            self.logger.info("Built docker image for service: {0}".format(service))

    def inspect_toolchain(self):
        """ Make sure we have all the right commands installed and configured.
        """
        for command in self.env_commands:
            try:
                # Run a test command for the utility, but silence the output
                subprocess.Popen([command[0], command[1]], stdout=self.devnull, stderr=self.devnull)
            except OSError as e:
                if e.errno == os.errno.ENOENT:
                    self.logger.error("You are missing this command: {0}".format(command[0]))
                    self.logger.error("Please install or activate {0}. {1}"
                                      .format(command[0], command[2]))
                sys.exit(1)
            self.logger.debug("Toolchain check passed for: {0}".format(command[0]))

        # docker-compose is installed, but we need to make sure our env is activated
        try:
            logger.info(self.build_dir)
            docker_dir = os.path.join(self.build_dir, 'docker')
            if os.path.exists(docker_dir):
                os.chdir(docker_dir)
                subprocess.Popen(['docker-compose', 'ps'], stdout=self.devnull, stderr=self.devnull)
                self.log("Toolchain check passed for docker")
        except subprocess.CalledProcessError as e:
            self.logger.error(
                    "docker-compose configuration error. Have you started your machine? \n" +
                    "Have you run `eval \"$(docker-machine env decipher-dev)\"`")
            sys.exit(1)

    def log(self, msg, log_level="INFO"):
        """
        Delegate to internal logger instance. Logging level is configurable, but defaults to INFO.
        """
        log_funcs = {'INFO': self.logger.info, 'DEBUG': self.logger.debug}
        fn = log_funcs.get(log_level, log_funcs['INFO'])
        fn(msg)

    def clone_branch(self, repo, repo_url, branch, build=True):
        """ Checkout git repository locally.
        
        Checkout our git dependencies into our target directory, one level up from OD_ROOT. The target directory
                is held as an instance variable `self.checkout_dir` on a Builder

        """

        if len(self.checkout_dir) > 0:

            checked_out_repo = os.path.join(self.checkout_dir, repo)
            if os.path.exists(checked_out_repo):
                self.logger.info("git repository {0} already checked out. Skipping clone...".format(repo))
                return
            try:
                # Checkout the repo to our checkout directory
                subprocess.check_call(
                        ['git', 'clone', '-b', branch, repo_url, checked_out_repo],
                        stdout=sys.stdout, stderr=sys.stderr)
            except subprocess.CalledProcessError as e:
                self.logger.error("Error from git clone: {0}".format(e))
                sys.exit(1)

            if build:
                self.build_project(checked_out_repo, repo)

        else:
            self.logger.warn("request to clone branch denied for {0} since checkout_dir is not established. must define OD_ROOT environment variable".format(repo))

    def build_project(self, checked_out_repo, repo):
        # cd into directory
        os.chdir(checked_out_repo)
        try:
            # Run `mvn package` if pom.xml exists.
            if os.path.exists(os.path.join(checked_out_repo, 'pom.xml')):
                subprocess.check_call(
                        ['mvn', 'clean', 'generate-sources', '-DskipTests'],
                        stdout=sys.stdout, stderr=sys.stderr)
                subprocess.check_call(
                        ['mvn', 'clean', 'package', '-DskipTests'],
                        stdout=sys.stdout, stderr=sys.stderr)
        except subprocess.CalledProcessError:
            self.logger.error("Build error for repository {0}".format(repo))
            sys.exit(1)

    def prerequisite_go_repo(self, go_import_path, branch):
        gopath = os.getenv('GOPATH')
        repository_directory = os.path.join(gopath, 'src', go_import_path)

        # Only clone the directory if it does not exist
        if os.path.exists(repository_directory):
            self.logger.info("git repository {0} already checked out. Skipping clone...".format(go_import_path))
        else:
            try:
                subprocess.check_call(
                        ['git', 'clone', '-b', branch, 'git@bitbucket.di2e.net/dime/object-drive-server.git',
                         repository_directory],
                        stdout=sys.stdout, stderr=sys.stderr)
            except subprocess.CalledProcessError as e:
                self.logger.error("Error from git clone: {0}".format(e))
                sys.exit(1)

        # Run `go get` to fetch Go depedencies and `go-bindata` to package static assets into Go source code
        try:
            database_directory = os.path.join(repository_directory, "cmd", "odrive-database")
            os.chdir(database_directory)
            self.log("Running go-bindata from this location: {0}".format(database_directory))
            subprocess.check_call(['go-bindata', 'schema', '../../defaultcerts/client-mysql/id', '../../defaultcerts/client-mysql/trust'])
            os.chdir(repository_directory)
            self.log("Running go get from this location: {0}".format(repository_directory))
            subprocess.check_call(['go', 'get', './...', ], stdout=sys.stdout, stderr=sys.stderr)
        except subprocess.CalledProcessError as e:
            self.logger.error("Error from go get: {0}".format(e))

    def clone_tag(self, repo, repo_url, tag):
        if len(self.checkout_dir) > 0:

            checked_out_repo = os.path.join(self.checkout_dir, repo)
            if os.path.exists(checked_out_repo):
                self.logger.info("git repository {0} already checked out. Skipping clone...".format(repo))
                return
            try:
                # Checkout the repo to our checkout directory
                subprocess.check_call(
                        ['git', 'clone', '--branch', tag, repo_url, checked_out_repo],
                        stdout=sys.stdout, stderr=sys.stderr)
            except subprocess.CalledProcessError as e:
                self.logger.error("Error from git clone: {0}".format(e))
                sys.exit(1)

            self.build_project(checked_out_repo, repo)
        else:
            self.logger.warn("request to clone tag denied for {0} since checkout_dir is not established. must define OD_ROOT environment variable".format(repo))


#-------------------------------------------------------------------------------

def setup_logging(log_file="odrive_build.log"):
    """ Configure logging module to handle the log stream 
    
    Logging will be output 
    
    Parameters:
    -----------
    log_file : str, opt
       filename to output log messages to
    
    """
    
    # create the logging file handler
    logging.basicConfig(filename=log_file,
                        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
                        level=logging.DEBUG)

    #-- handler for STDOUT
    ch = logging.StreamHandler(sys.stdout)
    ch.setLevel(logging.INFO)
    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    ch.setFormatter(formatter)
    logging.getLogger().addHandler(ch)

#-------------------------------------------------------------------------------

def parse_args():
    ''' Parse command line arguments.  
    
    Returns:
    --------
    args: argparse object
        
    parser: the parser itself    
    '''
    
    description = """Description: Object-Drive Build utility

    """
    
    default_images= ["deciphernow/odrive",
                     "deciphernow/odrive-bc",
                     "deciphernow/gatekeeper",
                     "deciphernow/metadatadb",
                     "deciphernow/odriverpm",
                     "deciphernow/odriverpm-bc",
                     "deciphernow/dias"]
    
    parser = argparse.ArgumentParser(formatter_class=argparse.RawDescriptionHelpFormatter,
                                     description=textwrap.dedent(description))

    parser.add_argument('--build', '-b', dest='build', action='store_true', default=False,
                        help="Build needed Object Drive images.")

    parser.add_argument('--clean', '-c', dest='clean', action='store_true', default=False,
                        help="Cleanup Object Drive related images.")

    parser.add_argument('--images', '-i', dest='images', nargs='*', type=str, default=default_images,
                        help='Images to build/clean.  Defaults to {0}'.format(default_images))

    parser.add_argument('--tag', '-t', dest='build_tag', type=str, default='latest',
                        help="Docker tag with which to build image[s].")

    parser.add_argument('--toolcheck', dest='toolcheck', action='store_true', default=False,
                        help='Inspect the local toolchain.')
    
    parser.add_argument('extra', nargs=argparse.REMAINDER, 
                        help='extra arguments supplied.  Will stop the command from running.')
    
    args = parser.parse_args()
    return args, parser

#-------------------------------------------------------------------------------

if __name__ == '__main__':
    opts, parser = parse_args()
    if opts.extra or not (opts.build or opts.clean or opts.toolcheck):
        sys.exit(parser.print_help())

    setup_logging()
    logger.info("Building Object Drive")
        
    builder = Builder(COMMANDS_REQUIRED, logger)

    if opts.toolcheck:
        builder.inspect_toolchain()

    if opts.clean:
        logger.info("cleaning images")
        clean_images(opts.images)

    if opts.build:
        if opts.images:
            for image in opts.images:
                logger.info("building image {0}".format(image))
                builder.build_named(image, tag=opts.build_tag)
        else:
            logger.info("building all images")
            builder.build_all()